{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textacy import extract\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads Spacy model\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# registers a token extension to store the tag to be used as delexicalization\n",
    "spacy.tokens.Token.set_extension('delexicalized_tag', default=None)\n",
    "\n",
    "# register a Token extension to work as getter of the delexicalized version of it\n",
    "#    if it's a delexicalized token, it should return its tag, else it shoudl return its text\n",
    "spacy.tokens.Token.set_extension('delexicalized_with_ws', getter=lambda token: token._.delexicalized_tag + token.whitespace_ if token._.delexicalized_tag else token.text_with_ws)\n",
    "\n",
    "# registers a Doc extension to work as getter of the delexicalized version of the full doc\n",
    "spacy.tokens.Doc.set_extension('delexicalized', getter=lambda doc: ''.join(t._.delexicalized_with_ws for t in doc))\n",
    "\n",
    "# function that receives a doc and a list of <tag, span> \n",
    "#    and merges the spans, so they are considered tokens\n",
    "#    and assign to the resulting token the tag\n",
    "def delexicalize_spans(doc, tag_span):\n",
    "    \n",
    "    for tag, span in tag_span:\n",
    "        \n",
    "        token = span.merge()\n",
    "        token._.delexicalized_tag = tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delexicalizing subject, verb, object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that delexicalizes a doc using its \n",
    "#    extracted subject, verb and objects\n",
    "#    using the textacy.extract module\n",
    "def delexicalize_svo(doc):\n",
    "    \n",
    "    svos = []\n",
    "\n",
    "    # for each <subject, verb, object> creates a list of <tag, span>\n",
    "    #    where tag is the corresponding role, added with the phrase index\n",
    "    for i, svo in enumerate(extract.subject_verb_object_triples(doc)):\n",
    "\n",
    "        svos.extend(zip([f'[subject-{i}]', f'[verb-{i}]', f'[object-{i}]'], svo))\n",
    "        \n",
    "    delexicalize_spans(doc, svos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Monday, Mr. Trump trained his attention on the Senate, where only four Republican votes are needed to pass the measure, should Democrats remain united, as expected. \n",
      "\n",
      "On Monday, [subject-0] [verb-0] his [object-0] on the Senate, where only four Republican votes are needed to pass the measure, should Democrats remain united, as expected. \n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "\n",
    "text = \"On Monday, Mr. Trump trained his attention on the Senate, where only four Republican votes are needed to pass the measure, should Democrats remain united, as expected.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "delexicalize_svo(doc)\n",
    "\n",
    "print(doc)\n",
    "\n",
    "print()\n",
    "\n",
    "print(doc._.delexicalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delexicalizing named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that delexicalizes a doc using its\n",
    "#    named entities\n",
    "#    extracted by the spacy model\n",
    "def delexicalize_ner(doc):\n",
    "    \n",
    "    ners = [(f'[{span.label_}]', span) for span in extract.named_entities(doc)]\n",
    "    \n",
    "    return delexicalize_spans(doc, ners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Monday, Mr. Trump trained his attention on the Senate, where only four Republican votes are needed to pass the measure, should Democrats remain united, as expected. \n",
      "\n",
      "On [DATE], Mr. [PERSON] trained his attention on the [ORG], where [CARDINAL] [NORP] votes are needed to pass the measure, should [NORP] remain united, as expected. \n"
     ]
    }
   ],
   "source": [
    "delexicalize_ner(doc)\n",
    "\n",
    "print(doc)\n",
    "\n",
    "print()\n",
    "\n",
    "print(doc._.delexicalized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
