{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "from textacy import extract\n",
    "import spacy\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/comp_sentences', 'r') as f:\n",
    "    \n",
    "    compressed_samples = [t[:-1] for t in islice(f, 0, 3)]\n",
    "    \n",
    "with open('../data/uncomp_sentences', 'r') as f:\n",
    "    \n",
    "    uncompressed_samples = [t[:-1] for t in islice(f, 0, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delexicalizing subject, verb, object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delexicalize_spans(text, to_delexicalize):\n",
    "    \n",
    "    text_char = list(text)\n",
    "\n",
    "    base = 0\n",
    "\n",
    "    for tag, span in sorted(to_delexicalize, key=lambda s: s[1].start_char):\n",
    "\n",
    "        text_char[base + span.start_char: base + span.end_char] = tag\n",
    "\n",
    "        len_span = span.end_char - span.start_char\n",
    "\n",
    "        base += len(tag) - len_span\n",
    "        \n",
    "    return ''.join(text_char)\n",
    "\n",
    "def delexicalize_svo(text):\n",
    "    \n",
    "    text_doc = nlp(text)\n",
    "\n",
    "    svos = []\n",
    "\n",
    "    for i, svo in enumerate(extract.subject_verb_object_triples(text_doc)):\n",
    "\n",
    "        svos.extend(zip([f'[subject-{i}]', f'[verb-{i}]', f'[object-{i}]'], svo))\n",
    "        \n",
    "    return delexicalize_spans(text, svos)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uncompressed:\n",
      "\n",
      "Serge Ibaka -- the Oklahoma City Thunder forward who was born in the Congo but played in Spain -- has been granted Spanish citizenship and will play for the country in EuroBasket this summer, the event where spots in the 2012 Olympics will be decided.\n",
      "\n",
      "delexicalized:\n",
      "\n",
      "[subject-0] [verb-0]City Thun[object-0] who was born in the Congo but played in Spain -- has been granted Spanish citizenship and will play for the country in EuroBasket this summer, the event where spots in the 2012 Olympics will be decided.\n",
      "\n",
      "compressed:\n",
      "\n",
      "Serge Ibaka has been granted Spanish citizenship and will play in EuroBasket.\n",
      "\n",
      "delexicalized:\n",
      "\n",
      "[subject-0] [verb-0] Spanish [object-0] and will play in EuroBasket.\n"
     ]
    }
   ],
   "source": [
    "print('uncompressed:\\n\\n{}\\n\\ndelexicalized:\\n\\n{}\\n\\ncompressed:\\n\\n{}\\n\\ndelexicalized:\\n\\n{}'\\\n",
    "      .format(uncompressed_samples[0],\n",
    "              delexicalize_svo(uncompressed_samples[0]),\n",
    "              compressed_samples[0],\n",
    "              delexicalize_svo(compressed_samples[0])\n",
    "             ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uncompressed:\n",
      "\n",
      "MILAN -Catania held Roma to a 1-1 draw in Serie A on Wednesday as the teams played out the remaining 25 minutes of a game that was called off last month.\n",
      "\n",
      "delexicalized:\n",
      "\n",
      "[subject-0] [verb-0] [object-0] to a 1-1 draw in Serie A on Wednesday as the [subject-1] [verb-1] out the remaining 25 [object-1] of a game that was called off last month.\n",
      "\n",
      "compressed:\n",
      "\n",
      "Catania held Roma to a 1 1 draw in Serie A.\n",
      "\n",
      "delexicalized:\n",
      "\n",
      "[subject-0] [verb-0] [object-0] to a 1 1 draw in Serie A.\n"
     ]
    }
   ],
   "source": [
    "print('uncompressed:\\n\\n{}\\n\\ndelexicalized:\\n\\n{}\\n\\ncompressed:\\n\\n{}\\n\\ndelexicalized:\\n\\n{}'\\\n",
    "      .format(uncompressed_samples[1],\n",
    "              delexicalize_svo(uncompressed_samples[1]),\n",
    "              compressed_samples[1],\n",
    "              delexicalize_svo(compressed_samples[1])\n",
    "             ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delexicalizing named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "def delexicalize_ner(text):\n",
    "    \n",
    "    text_doc = nlp(text)\n",
    "    \n",
    "    ners = [(f'[{span.label_}]', span) for span in extract.named_entities(text_doc)]\n",
    "    \n",
    "    return delexicalize_spans(text, ners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uncompressed:\n",
      "\n",
      "Serge Ibaka -- the Oklahoma City Thunder forward who was born in the Congo but played in Spain -- has been granted Spanish citizenship and will play for the country in EuroBasket this summer, the event where spots in the 2012 Olympics will be decided.\n",
      "\n",
      "delexicalized:\n",
      "\n",
      "[PERSON] -- the [GPE] City Thunder forward who was born in the [GPE] but played in [GPE] -- has been granted [NORP] citizenship and will play for the country in [GPE] this [DATE], the event where spots in the [EVENT] will be decided.\n",
      "\n",
      "compressed:\n",
      "\n",
      "Serge Ibaka has been granted Spanish citizenship and will play in EuroBasket.\n",
      "\n",
      "delexicalized:\n",
      "\n",
      "[PERSON] has been granted [NORP] citizenship and will play in [ORG].\n"
     ]
    }
   ],
   "source": [
    "print('uncompressed:\\n\\n{}\\n\\ndelexicalized:\\n\\n{}\\n\\ncompressed:\\n\\n{}\\n\\ndelexicalized:\\n\\n{}'\\\n",
    "      .format(uncompressed_samples[0],\n",
    "              delexicalize_ner(uncompressed_samples[0]),\n",
    "              compressed_samples[0],\n",
    "              delexicalize_ner(compressed_samples[0])\n",
    "             ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delexicalize everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## svo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.89 s, sys: 15.6 ms, total: 2.91 s\n",
      "Wall time: 767 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open('../data/comp_sentences', 'r') as f_in, open('../data/delex_svo_comp_sentences', 'w') as f_out:\n",
    "        \n",
    "    for line in islice(f_in, 0, 100):\n",
    "        \n",
    "        text = line[:-1]\n",
    "        \n",
    "        delex_text = delexicalize_svo(f'{text}\\n')\n",
    "        \n",
    "        f_out.write(delex_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.61 s, sys: 0 ns, total: 3.61 s\n",
      "Wall time: 950 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open('../data/uncomp_sentences', 'r') as f_in, open('../data/delex_svo_uncomp_sentences', 'w') as f_out:\n",
    "        \n",
    "    for line in islice(f_in, 0, 100):\n",
    "        \n",
    "        text = line[:-1]\n",
    "        \n",
    "        delex_text = delexicalize_svo(f'{text}\\n')\n",
    "        \n",
    "        f_out.write(delex_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.86 s, sys: 15.6 ms, total: 2.88 s\n",
      "Wall time: 771 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open('../data/comp_sentences', 'r') as f_in, open('../data/delex_ner_comp_sentences', 'w') as f_out:\n",
    "        \n",
    "    for line in islice(f_in, 0, 100):\n",
    "        \n",
    "        text = line[:-1]\n",
    "        \n",
    "        delex_text = delexicalize_ner(f'{text}\\n')\n",
    "        \n",
    "        f_out.write(delex_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.34 s, sys: 0 ns, total: 3.34 s\n",
      "Wall time: 898 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open('../data/uncomp_sentences', 'r') as f_in, open('../data/delex_ner_uncomp_sentences', 'w') as f_out:\n",
    "        \n",
    "    for line in islice(f_in, 0, 100):\n",
    "        \n",
    "        text = line[:-1]\n",
    "        \n",
    "        delex_text = delexicalize_ner(f'{text}\\n')\n",
    "        \n",
    "        f_out.write(delex_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
